{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lCRZaic68eLe"},"outputs":[],"source":["# Performance Metrics (Monthly)\n","Using the classification method for the returns, with ESS features in AI/ML\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","%run import_library.ipynb\n","\n","file = open('outputs/finalised_df/df_cn_month.pickle', \"rb\")\n","df = pickle.load(file)\n","\n","for_testing_df = df.copy()\n","sedol_list = list(df.sedol.unique())\n","df\n","\n","# check the list of starting date\n","sedol_dates = {}\n","\n","for s in sedol_list:\n","    temp_df = df[df['sedol'] == s]\n","    date = list(temp_df.index)[0]\n","    sedol_dates[s] = date\n","\n","sedol_dates\n","\n","### Various Assumptions Involved:\n","1. At the end of the trading day, the team will make a decision for the next day given the collated datasets for the day\n","2. Predicting the next day's price, and comparing the result against the actual closing price.\n","\n","# model parameters\n","\n","sentiment = False\n","finalised_model = xgb_monthly_combined\n","frequency = \"M\"\n","test_date = \"2019-01-01\" # sync this test date with script 04, where the train test split date is being stated\n","\n","### Optimize Quantile\n","Purpose: To optimize quantile for all individual firms based on best excess returns. Note: not a general quantile for financial sector, it is customise individually for each firms.\n","\n","# run through sedol, companies specific. Note: Long run time (roughly 45 mins)\n","%time\n","\n","quantile_dict = {}\n","predict_dict = {} # prediction results for companies\n","\n","for i in sedol_list:    \n","    \n","    temp_df = df[(df['sedol'] == i)] # fitler and concat them\n","    temp_df.sort_index(axis=0, ascending=True, inplace=True)\n","    temp_df['returns_movement'] = temp_df.apply(lambda x: returns_movement(x), axis=1) # y true for the next week data\n","\n","    # train test split - get the date\n","    train_df = temp_df[temp_df.index < test_date]\n","    test_df = temp_df[temp_df.index >= test_date]\n","\n","    if train_df.empty: # if the df date is after test date\n","        best_performance_values = [0.9, 0.15, 0.5, 2.0]\n","        quantile_dict[i] = [best_performance_values, \"nil\"]\n","        \n","    else:\n","        # using train data to tune for optimal quantile\n","        best_performance_values, best_excess_return = optimize_quantile(train_df, i, finalised_model, sentiment, frequency, 0.90)\n","        quantile_dict[i] = [best_performance_values, best_excess_return]\n","\n","    # best performance values based on excess returns tuning\n","    quantile = best_performance_values[0]\n","    ess_threshold = best_performance_values[1]\n","    returns_threshold = best_performance_values[2]\n","    news_spikes_threshold = best_performance_values[3]\n","    \n","    # using test data\n","    curr_df = prediction_processing(test_df, finalised_model, sentiment, frequency, quantile, ess_threshold, returns_threshold, news_spikes_threshold)\n","    predict_dict[i] = curr_df # for test dataset\n","\n","### Classification Performance Metrics\n","To understand the timing of the price movement is conclusive from the sentiment movements\n","\n","quantile_dict\n","\n","counter = 0\n","for s, df in predict_dict.items(): # s for sedol, df for performance dataframe\n","    \n","    # creating the performance metrics for all the firms\n","    df = performance(df, s, frequency)\n","    \n","    if counter == 0: # initiate 1st df\n","        performance_df =  pd.DataFrame(df,index=['Annualised Return (Buy Hold)','Annualised Return (Sentiment)','Annualised Excess Return', 'Winrate', \"Annualised Turnover\", 'Volatility (Buy Hold)', 'Volatility (Sentiment)', 'Max Drawdown (Buy Hold)', 'Max Drawdown (Sentiment)',\"Cumulative Return (Buy Hold)\", \"Cumulative Return (Sentiment)\", 'Sharpe Ratio', 'F1 Score', \"Precision\"], columns=[s])\n","    \n","    else:\n","        performance_df[s] = df\n","    \n","    counter = counter + 1\n","\n","performance_df = perf_format(performance_df)\n","performance_df\n","\n","### Summary of Individual Firm Performance Metrics\n","Combine all the 30 holdings (listed in HK Exchange)\n","\n","# absoulte & cumulative returns chart\n","import plotly.graph_objects as go\n","import numpy as np\n","\n","ldf_abs_returns_fig = []\n","ldf_cum_returns_fig = []\n","\n","for s, df in predict_dict.items(): # s for sedol, df for performance dataframe\n","    \n","    entity_name = df['entity_name'][0]\n","    \n","    # cumulative returns\n","    fig_cum_returns = go.Figure()\n","\n","    # Add traces\n","    fig_cum_returns.add_trace(go.Scatter(x=df.index, y=df['return_mp_cum'], name=f\"{entity_name} Sentiment Strategy\"))\n","    fig_cum_returns.add_trace(go.Scatter(x=df.index, y=df['return_bm_cum'], name=f\"{entity_name} Buy Hold Strategy\"))\n","    fig_cum_returns.update_layout(\n","        title=f\"{entity_name} Cumulative Returns\",\n","        xaxis_title=\"Time Period\",\n","        yaxis_title=\"Cumulative Returns\"\n","    )\n","    \n","    # absolute returns\n","    fig_abs_returns = go.Figure()\n","\n","    # Add traces\n","    fig_abs_returns.add_trace(go.Scatter(x=df.index, y=df['return_mp'], name=f\"{entity_name} Sentiment Strategy\"))\n","    fig_abs_returns.add_trace(go.Scatter(x=df.index, y=df['return_bm'], name=f\"{entity_name} Buy Hold Strategy\"))\n","    fig_abs_returns.update_layout(\n","        title=f\"{entity_name} Absolute Returns\",\n","        xaxis_title=\"Time Period\",\n","        yaxis_title=\"Absolute Returns\"\n","    )\n","    ldf_cum_returns_fig.append(fig_cum_returns)\n","    ldf_abs_returns_fig.append(fig_abs_returns)\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import ipywidgets as widgets\n","\n","out1 = widgets.Output()\n","out2 = widgets.Output()\n","out3 = widgets.Output()\n","\n","tab = widgets.Tab(children = [out1, out2, out3])\n","tab.set_title(0, 'Overview')\n","tab.set_title(1, 'Individual Firms (Cumulative Returns)')\n","tab.set_title(2, 'Individual Firms (Absolute Returns)')\n","display(tab)\n","\n","with out1:\n","    final_performance_df = performance_df.copy().style.set_caption(\"Overview of Individual Firms Performance\")\n","    display(final_performance_df)\n","\n","with out2:\n","    for fig in ldf_cum_returns_fig:\n","        display(fig)\n","    \n","with out3:\n","    for fig in ldf_abs_returns_fig:\n","        display(fig)\n","\n","### Pre-Assign Train Dataset For Script 06 Optimization\n","\n","predict_train_dict = {}\n","count = 0\n","for k, v in quantile_dict.items():\n","    count = count + 1\n","    best_performance_values = v[0]\n","    temp_df = for_testing_df[(for_testing_df['sedol'] == k)] # filter\n","    temp_df.sort_index(axis=0, ascending=True, inplace=True)\n","    temp_df['returns_movement'] = temp_df.apply(lambda x: returns_movement(x), axis=1) # y true for the next week data\n","\n","    # best performance values based on excess returns tuning\n","    quantile = best_performance_values[0]\n","    ess_threshold = best_performance_values[1]\n","    returns_threshold = best_performance_values[2]\n","    news_spikes_threshold = best_performance_values[3]\n","    \n","    # using test data\n","    curr_df = prediction_processing(temp_df, finalised_model, sentiment, frequency, quantile, ess_threshold, returns_threshold, news_spikes_threshold)\n","    predict_train_dict[k] = curr_df # for test dataset\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNS2bXPyzvprYJkJwn0KbW6","collapsed_sections":[],"name":"C_05_Monthly_Performance_&_Strategy_Metrics.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
